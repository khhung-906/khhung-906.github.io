<!DOCTYPE HTML>
<html lang="en">
  <head>
    <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

    <title>Kuo-Han (Johnson) Hung</title>

    <meta name="author" content="Kuo-Han Hung">
    <meta name="viewport" content="width=device-width, initial-scale=1">

    <link rel="stylesheet" type="text/css" href="stylesheet.css">
    <link rel="icon" href="data:image/svg+xml,<svg xmlns=%22http://www.w3.org/2000/svg%22 viewBox=%220 0 100 100%22><text y=%22.9em%22 font-size=%2290%22>ðŸ¤–</text></svg>">
  </head>

  <body>
    <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
      <tr style="padding:0px">
        <td style="padding:0px">
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr style="padding:0px">
              <td style="padding:2.5%;width:63%;vertical-align:middle">
                <p class="name" style="text-align: center;">
                  Kuo-Han (Johnson) Hung
                </p>
                <p> I am a senior undergrad majoring in Computer Science at National Taiwan University. I am advised by Prof. <a href="https://winstonhsu.info/">Winston H. Hsu</a> and Prof. <a href="https://www.csie.ntu.edu.tw/~yvchen/">Yun-Nung (Vivian) Chen</a>. My primary research interests lie in robot learning and multi-modal learning, and I have also conducted research in trustworthy AI.
                </p>
                <p style="text-align:center">
                  <a href="mailto:johnson090626@gmail.com">Email</a> &nbsp;/&nbsp;
                  <a href="data/CV_kuo_han_hung.pdf">CV</a> &nbsp;/&nbsp;
                  <a href="https://scholar.google.com/citations?user=_L9iSdoAAAAJ&hl=en&authuser=1">Google Scholar</a> &nbsp;/&nbsp;
                  <a href="https://github.com/khhung906">Github</a> &nbsp;/&nbsp;
                  <a href="https://www.linkedin.com/in/johnson-hung-axz906/">LinkedIn</a>
                </p>
              </td>
              <td style="padding:2.5%;width:25%;max-width:25%">
                <a href="images/Johnson.jpg"><img style="width:100%;max-width:100%" alt="profile photo" src="images/Johnson.jpg" class="hoverZoomLink"></a>
              </td>
            </tr>
          </tbody></table>

          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
              <tr>
              <td style="padding:20px;width:100%;vertical-align:middle">
                <h2>Research</h2>
                <p>
                  I'm boardly interesteed in machine learning, robotics, multi-modal learning, and trustworthy AI.
                </p>
              </td>
            </tr>
          </tbody></table>
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
              <td style="padding:20px;width:25%;vertical-align:middle">
                <div class="one">
                  <img src='images/victor.png' width="170">
                </div>
              </td>
              <td style="padding:20px;width:75%;vertical-align:middle">
                <a href="https://arxiv.org/abs/2405.16545">
                  <span class="papertitle">VICtoR: Learning Hierarchical Vision-Instruction Correlation Rewards for Long-horizon Manipulation</span>
                </a>
                <br>
                <strong>Kuo-Han Hung*</strong>, Pang-Chi Lo*, Jia-Fong Yeh*, Han-Yuan Hsu, Yi-Ting Chen, Winston H. Hsu
                <br>
                <em>ICML 2024 workshop: Aligning Reinforcement Learning Experimentalists and Theorists</em>
                <br>
                <a href="https://arxiv.org/abs/2405.16545">paper</a>
                <p></p>
                <p>
                  Existing Vision-Instruction Correlation (VIC) reward models struggle with training for long-horizon tasks. We propose VICtoR, a new reward model for long-horizon robotic reinforcement learning that assigns rewards hierarchically.
                </p>
              </td>
            </tr>
            <tr>
              <td style="padding:20px;width:25%;vertical-align:middle">
                <div class="one">
                  <img src='images/aed.png' width="140">
                </div>
              </td>
              <td style="padding:20px;width:75%;vertical-align:middle">
                <a href="https://arxiv.org/abs/2402.03860">
                  <span class="papertitle">AED: Adaptable Error Detection for Few-shot Imitation Policy</span>
                </a>
                <br>
                Jia-Fong Yeh, <strong>Kuo-Han Hung*</strong>, Pang-Chi Lo*, Chi-Ming Chung, Tsung-Han Wu, Hung-Ting Su, Yi-Ting Chen, Winston H Hsu
                <br>
                <em>Preprint</em>
                <br>
                <a href="https://arxiv.org/abs/2402.03860">paper</a>
                <p></p>
                <p>
                  The novel adaptable error detection (AED) problem is formulated for monitoring few-shot imitation policies' behaviors, and we propose PrObe to address the challenging problem by learning from the policy's feature representations.
                </p>
              </td>
            </tr>
            <tr>
              <td style="padding:20px;width:25%;vertical-align:middle">
                <div class="one">
                  <img src='images/conv.png' width="170">
                </div>
              </td>
              <td style="padding:20px;width:75%;vertical-align:middle">
                <a href="https://arxiv.org/abs/2211.09401">
                  <span class="papertitle">Open-domain conversational question answering with historical answers</span>
                </a>
                <br>
                Hung-Chieh Fang*, <strong>Kuo-Han Hung*</strong>, Chao-Wei Huang, Yun-Nung Chen
                <br>
                <em>AACL 2022</em>
                <br>
                <a href="https://arxiv.org/abs/2211.09401">paper</a> / <a href="https://github.com/MiuLab/ConvADR-QA">code</a>
                <p></p>
                <p>
                  Open-domain conversational question answering combines passage retrieval and answering, with ConvADR-QA leveraging historical answers to improve both tasks. Our model outperforms baselines on OR-QuAC by reducing noise through a teacher-student framework.
                </p>
              </td>
            </tr>
          </tbody></table>
          <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20"><tbody>
            <tr>
              <td>
                <h2>Professional Experience</h2>
              </td>
            </tr>
          </tbody></table>
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
              <td style="padding:20px;width:25%;vertical-align:middle">
                <div class="one" style="display: flex; justify-content: center; align-items: center;">
                  <img src="images/ibm_research.png" width="150">
                </div>
              </td>
              <td style="padding:20px;width:75%;vertical-align:middle">
                  <papertitle>Research Intern, IBM research</papertitle>
                <br>
                Summer 2024
                <br>
                <p>Advised by Dr. Pin-Yu Chen.</p>
                <p>Research in trustworthy AI.</p>
              </td>
            </tr>
          </tbody></table>

          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
              <td style="padding:20px;width:25%;vertical-align:middle">
                <div class="one" style="display: flex; justify-content: center; align-items: center;">
                  <img src="images/microsoft.png" width="220">
                </div>
              </td>
              <td style="padding:20px;width:75%;vertical-align:middle">
                  <papertitle>Applied Scientist Intern, Microsoft</papertitle>
                <br>
                Jul. 2023 - Jun. 2024
                <br>
                <p>Integrated Bing Maps services and context-aware map search system with Microsoft Copilot for complicated map quires.</p>
                <p>Developed a new path finding algorithm that learns from historical data to achieve over a 10x speedup.</p>
              </td>
            </tr>
          </tbody></table>
          
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
              <td style="padding:0px">
                <br>
                <p style="text-align:right;font-size:small;">
                  Website template is adapted from <a href="https://github.com/jonbarron/jonbarron_website">here</a>.
                </p>
              </td>
            </tr>
          </tbody></table>
        </td>
      </tr>
    </table>
  </body>
</html>

