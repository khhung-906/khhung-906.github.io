{
  "news_list": [
    {
      "date": "May. 2025",
      "news": "Excited to join Stanford University for MSCS this fall - see you in the Bay Area!"
    },
    {
      "date": "Jan. 2025",
      "news": "Our paper <strong>VICtoR</strong> is accepted by <strong>ICLR 2025</strong>!"
    },
    {
      "date": "Jan. 2025",
      "news": "Our paper <strong>Attention Tracker</strong> is accepted by <strong>NAACL 2025</strong>!"
    },
    {
      "date": "Sep. 2024",
      "news": "Our paper <strong>AED</strong> is accepted by <strong>NeurIPS 2024</strong>!"
    }
  ],
  "paper_list": [
    {
      "title": "Attention Tracker: Detecting Prompt Injection Attacks in LLMs",
      "image": "images/attention.png",
      "authors": "<strong>Kuo-Han Hung</strong>, Ching-Yun Ko, Ambrish Rawat, I-Hsin Chung, Winston H. Hsu, Pin-Yu Chen",
      "conference": "Annual Conference of the Nations of the Americas Chapter of the Association for Computational Linguistics (NAACL) 2025",
      "paper_link": "https://arxiv.org/abs/2411.00348",
      "code_link": "https://github.com/khhung-906/Attention-Tracker",
      "page_link": "https://huggingface.co/spaces/TrustSafeAI/Attention-Tracker",
      "abstract": "LLM-integrated application (ex. LLM agent) excel across domains but remain vulnerable to prompt injection attacks. We introduce Attention Tracker, a training-free detection method that monitors attention patterns to identify such attacks without requiring additional LLM inference."
    },
    {
      "title": "VICtoR: Learning Hierarchical Vision-Instruction Correlation Rewards for Long-horizon Manipulation",
      "image": "images/victor.png",
      "authors": "<strong>Kuo-Han Hung*</strong>, Pang-Chi Lo*, Jia-Fong Yeh*, Han-Yuan Hsu, Yi-Ting Chen, Winston H. Hsu",
      "conference": "International Conference on Learning Representations (ICLR) 2025",
      "paper_link": "https://arxiv.org/abs/2405.16545",
      "code_link": "",
      "page_link": "https://cmlab-victor.github.io/cmlab-vicotor.github.io/",
      "abstract": "Existing Vision-Instruction Correlation (VIC) reward models struggle with training for long-horizon tasks. We propose VICtoR, a new reward model for long-horizon robotic reinforcement learning that assigns rewards hierarchically."
    },
    {
      "title": "AED: Adaptable Error Detection for Few-shot Imitation Policy",
      "image": "images/aed.png",
      "authors": "Jia-Fong Yeh, <strong>Kuo-Han Hung*</strong>, Pang-Chi Lo*, Chi-Ming Chung, Tsung-Han Wu, Hung-Ting Su, Yi-Ting Chen, Winston H Hsu",
      "conference": "Conference on Neural Information Processing System (NeurIPS) 2024",
      "paper_link": "https://arxiv.org/abs/2402.03860",
      "code_link": "",
      "page_link": "https://aed-neurips.github.io/#",
      "abstract": "The novel adaptable error detection (AED) problem is formulated for monitoring few-shot imitation policies' behaviors, and we propose PrObe to address the challenging problem by learning from the policy's feature representations."
    },
    {
      "title": "Customizable Routing with Learnings from Past Recommendations",
      "image": "images/map.png",
      "authors": "<strong>Kuo-Han Hung</strong>, Chiqun Zhang, Dragomir Yankov",
      "conference": "ACM SIGSPATIAL 2024",
      "paper_link": "https://dl.acm.org/doi/10.1145/3678717.3691327",
      "code_link": "",
      "page_link": "",
      "abstract": "Finding routes is essential for map services, yet most methods overlook user-specific preferences. We introduce a novel approach that uses historical route data to filter irrelevant paths and incorporates query semantics, like "route from Seattle to Redmond with fewer traffic lights,
      " for optimized, preference-aware routing."
    },
    {
      "title": "Open-domain conversational question answering with historical answers",
      "image": "images/conv.png",
      "authors": "Hung-Chieh Fang*, <strong>Kuo-Han Hung*</strong>, Chao-Wei Huang, Yun-Nung Chen",
      "conference": "Annual Conference of the Asian Chapter of the Association for Computational Linguistics (AACL) 2022",
      "paper_link": "https://arxiv.org/abs/2211.09401",
      "code_link": "https://github.com/MiuLab/ConvADR-QA",
      "abstract": "Open-domain conversational question answering combines passage retrieval and answering, with ConvADR-QA leveraging historical answers to improve both tasks. Our model outperforms baselines on OR-QuAC by reducing noise through a teacher-student framework."
    }
  ],
  "exp_list": [
    {
      "title": "Research Intern, IBM research",
      "image": "images/ibm_research.png",
      "date": "Jun. 2024 - Sep. 2024",
      "advisor": "Advised by <a href='https://sites.google.com/site/pinyuchenpage/'>Dr. Pin-Yu Chen</a>",
      "intro": "Research in trustworthy AI."
    },
    {
      "title": "Applied Scientist Intern, Microsoft",
      "image": "images/microsoft.png",
      "date": "Jul. 2023 - Jun. 2024",
      "advisor": "Advised by <a href='https://chiqunz.github.io/'>Dr. Chiqun Zhang</a>",
      "intro": "Integrated Bing Maps services and context-aware map search system with Microsoft Copilot for complicated map quires; Developed a new path finding algorithm that learns from historical data to achieve over a 10x speedup."
    }
  ],
  "project_list": [
    {
      "title": "Vulnerabilities in VLM-Powered Policies",
      "source": "Course Project of Security and Privacy of ML, Spring 2024",
      "image": "images/vul_policy.png",
      "slide_link": "https://docs.google.com/presentation/d/1uE96UYIB6Sy6T1XGx58W7zIbceSfLbVzbuZMOTgJFFs/edit?usp=sharing",
      "abstract": "Developed a text and image-based adversarial attack method to manipulate embodied AI behavior, achieving a 40% increase in targeted attack success on VLM-powered policy networks."
    },
    {
      "title": "Zero-shot Text Behavior Retrieval",
      "source": "Course Project of Reinforcement Learning, Fall 2023",
      "image": "images/text_br.png",
      "paper_link": "data/Text_Behavior_Retrieval.pdf",
      "abstract": "We propose a method for retrieving task-relevant data for imitation learning without requiring expert demonstrations. Our approach leverages text descriptions in combination with a vision-language model to enable zero-shot behavior retrieval."
    }
  ]
}